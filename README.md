# Image_deepfake_detection
Deepfake Detection

This repository contains code for detecting deepfake images using a combination of ViT (Vision Transformer), autoencoder models and XGBoost. Deepfake images are synthetic images generated by deep learning algorithms to replace or manipulate the content of original images or videos, often used for malicious purposes such as spreading misinformation or creating fraudulent content.

I have implemented the paper titled “Towards Universal Fake Image Detectors that Generalize Across Generative Models”. This Paper explored the approach of not training the backbone model of ViT and instead using its embedding vectors to create a high dimentional feature Space to plot Real and Fake images. Upon this feature space, the paper proposes to use a KNN classifier to test unseen images. I have instead reduced the image space dimention using an autoencoder and used XGBoost as the classifier.   

Paper link : https://arxiv.org/abs/2302.10174
Dataset:
GAN dataset: https://drive.google.com/file/d/1z_fD3UKgWQyOTZIBbYSaQ-hz4AzUrLC1/view 
DM dataset : https://drive.google.com/file/d/1FXlGIRh_Ud3cScMgSVDbEWmPDmjcrm1t/view

Further Details:
ViT Transformer used: CLIP ViT B-16 and ImageNet ViT B-16
Autoencoder latent dimention : 200

Accuracies for XGBoost (embedded):

Dalle:
•	ImageNet ViT: 83.44%
•	Clip ViT: 83.77%

Glide 100 27
•	ImageNet ViT: 90.61%
•	Clip ViT: 87.68%

Dependencies:
•	Python (>=3.6)
•	PyTorch
•	Transformers library 
•	scikit-learn
•	SciPy
•	PIL
•	NumPy
•	Pandas

Usage:

As the project was developed on Google Colab, the code is available in the form of a Jupyter Notebook (.ipynb). You can directly access and run the notebook on Google Colab by uploading the .ipynb file to your Colab environment.
